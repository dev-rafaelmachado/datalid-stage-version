# ğŸ¯ DetecÃ§Ã£o YOLO

> Sistema de detecÃ§Ã£o e segmentaÃ§Ã£o de regiÃµes de datas de validade usando YOLOv8

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Arquitetura YOLOv8](#arquitetura-yolov8)
- [Modelos DisponÃ­veis](#modelos-disponÃ­veis)
- [ConfiguraÃ§Ã£o](#configuraÃ§Ã£o)
- [Uso](#uso)
- [SegmentaÃ§Ã£o vs Detection](#segmentaÃ§Ã£o-vs-detection)
- [OtimizaÃ§Ã£o](#otimizaÃ§Ã£o)

## ğŸ¯ VisÃ£o Geral

O Datalid usa **YOLOv8-seg** (segmentaÃ§Ã£o de instÃ¢ncias) para:
- ğŸ¯ **Localizar** regiÃµes com datas de validade
- ğŸ—ºï¸ **Segmentar** contornos precisos (mÃ¡scara poligonal)
- ğŸ“Š **Classificar** tipos de regiÃµes (se necessÃ¡rio)
- âš¡ **Processar** em tempo real (GPU)

**Por que YOLO?**
- âœ… State-of-the-art em velocidade e precisÃ£o
- âœ… Single-stage detector (rÃ¡pido)
- âœ… Suporta segmentaÃ§Ã£o de instÃ¢ncias
- âœ… FÃ¡cil de treinar e customizar
- âœ… Excelente documentaÃ§Ã£o e comunidade

## ğŸ—ï¸ Arquitetura YOLOv8

### Estrutura do Modelo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           INPUT IMAGE                     â”‚
â”‚         (640x640x3 RGB)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         BACKBONE (CSPDarknet)            â”‚
â”‚  - ExtraÃ§Ã£o hierÃ¡rquica de features      â”‚
â”‚  - Multi-scale feature maps              â”‚
â”‚  - P3, P4, P5 (diferentes resoluÃ§Ãµes)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         NECK (PANet)                     â”‚
â”‚  - Feature pyramid network               â”‚
â”‚  - Path aggregation                      â”‚
â”‚  - FusÃ£o multi-escala                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         DETECTION HEAD                    â”‚
â”‚  - Bounding boxes (x, y, w, h)           â”‚
â”‚  - Confidence scores                     â”‚
â”‚  - Class probabilities                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         SEGMENTATION HEAD                 â”‚
â”‚  - Mask coefficients (32 channels)       â”‚
â”‚  - Proto masks (160x160x32)              â”‚
â”‚  - Instance segmentation                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         POST-PROCESSING                   â”‚
â”‚  - NMS (Non-Maximum Suppression)         â”‚
â”‚  - Confidence filtering                  â”‚
â”‚  - Mask generation                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         OUTPUT                            â”‚
â”‚  - Boxes: [x1, y1, x2, y2]               â”‚
â”‚  - Masks: Polygon coordinates            â”‚
â”‚  - Scores: Confidence values             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes Principais

#### 1. Backbone (CSPDarknet)
```python
# Feature extraction em mÃºltiplas escalas
P3: (80x80) - Objetos pequenos
P4: (40x40) - Objetos mÃ©dios  
P5: (20x20) - Objetos grandes
```

#### 2. Neck (PANet)
```python
# AgregaÃ§Ã£o de features
Bottom-up: P3 â†’ P4 â†’ P5 (captura contexto)
Top-down: P5 â†’ P4 â†’ P3 (refina detalhes)
```

#### 3. Detection Head
```python
# Para cada anchor:
- tx, ty, tw, th: Box coordinates
- objectness: Confidence score
- class_probs: [P(class1), P(class2), ...]
```

#### 4. Segmentation Head
```python
# Mask generation:
- Mask coefficients: 32 valores por instÃ¢ncia
- Proto masks: Base masks (160x160x32)
- Final mask = Linear combination of proto masks
```

## ğŸ“¦ Modelos DisponÃ­veis

### YOLOv8 Variants

| Modelo | ParÃ¢metros | FLOPs | mAP@50 | Velocidade (GPU) | Uso Recomendado |
|--------|-----------|-------|---------|------------------|-----------------|
| **YOLOv8n-seg** | 3.4M | 12.6G | 37.2 | **80 FPS** | ğŸš€ ProduÃ§Ã£o (rÃ¡pido) |
| **YOLOv8s-seg** | 11.8M | 42.6G | 44.6 | 60 FPS | âš–ï¸ Balanceado |
| **YOLOv8m-seg** | 27.3M | 110.2G | 49.9 | 35 FPS | ğŸ¯ Alta precisÃ£o |
| **YOLOv8l-seg** | 46.0M | 220.5G | 52.3 | 20 FPS | ğŸ”¬ Pesquisa |
| **YOLOv8x-seg** | 71.8M | 344.1G | 53.4 | 12 FPS | ğŸ† MÃ¡xima precisÃ£o |

### Qual Modelo Escolher?

**Para ProduÃ§Ã£o (Tempo Real):**
```yaml
detection:
  model_path: yolov8n-seg.pt  # Nano
  imgsz: 640
  conf: 0.25
```

**Para Melhor PrecisÃ£o:**
```yaml
detection:
  model_path: yolov8m-seg.pt  # Medium
  imgsz: 1280  # Maior resoluÃ§Ã£o
  conf: 0.15   # Threshold menor
```

**Para CPU:**
```yaml
detection:
  model_path: yolov8n-seg.pt  # Nano (Ãºnico viÃ¡vel)
  imgsz: 480   # ResoluÃ§Ã£o menor
  half: false  # FP32 (sem FP16)
```

## âš™ï¸ ConfiguraÃ§Ã£o

### Arquivo de ConfiguraÃ§Ã£o

```yaml
# config/yolo/detection.yaml

detection:
  # Modelo
  model_path: yolov8n-seg.pt
  device: cuda  # cuda, cpu, mps (Apple Silicon)
  
  # Inference
  imgsz: 640            # Tamanho de entrada (mÃºltiplo de 32)
  conf: 0.25            # Confidence threshold
  iou: 0.45             # IoU threshold para NMS
  max_det: 10           # MÃ¡ximo de detecÃ§Ãµes por imagem
  
  # SegmentaÃ§Ã£o
  retina_masks: true    # MÃ¡scaras em alta resoluÃ§Ã£o
  
  # Performance
  half: true            # FP16 (requer GPU)
  batch_size: 1         # Batch processing
  
  # Augmentation (inference)
  augment: false        # Test-time augmentation (TTA)
  
  # Crop settings
  crop_padding: 10      # Pixels de margem no crop
  min_crop_size: 20     # Tamanho mÃ­nimo do crop
```

### ConfiguraÃ§Ã£o ProgramÃ¡tica

```python
from ultralytics import YOLO

# Carregar modelo
model = YOLO('yolov8n-seg.pt')

# Configurar device
model.to('cuda')

# Inference com parÃ¢metros customizados
results = model.predict(
    source='image.jpg',
    imgsz=640,
    conf=0.25,
    iou=0.45,
    max_det=10,
    retina_masks=True,
    half=True,
    verbose=False
)
```

## ğŸš€ Uso

### Uso BÃ¡sico

```python
from src.pipeline.detection import DetectionPipeline
from src.ocr.config import load_pipeline_config

# Carregar configuraÃ§Ã£o
config = load_pipeline_config('config/pipeline/full_pipeline.yaml')

# Criar pipeline de detecÃ§Ã£o
detector = DetectionPipeline(config)

# Processar imagem
result = detector.process('product_image.jpg')

# Acessar resultados
print(f"DetecÃ§Ãµes: {len(result['detections'])}")
for det in result['detections']:
    print(f"  BBox: {det['bbox']}")
    print(f"  ConfianÃ§a: {det['confidence']:.2%}")
    print(f"  Ãrea: {det['area']} pixels")
```

### DetecÃ§Ã£o em Batch

```python
# MÃºltiplas imagens
images = ['img1.jpg', 'img2.jpg', 'img3.jpg']
results = detector.process_batch(images)

for img, result in zip(images, results):
    print(f"{img}: {len(result['detections'])} detecÃ§Ãµes")
```

### ExtraÃ§Ã£o de Crops

```python
import cv2
from src.yolo.utils import extract_crops

# Carregar imagem
image = cv2.imread('product.jpg')

# Detectar
result = detector.process(image)

# Extrair crops das regiÃµes detectadas
crops = extract_crops(
    image,
    result['detections'],
    padding=10,
    use_mask=True  # Aplicar mÃ¡scara de segmentaÃ§Ã£o
)

# Salvar crops
for i, crop in enumerate(crops):
    cv2.imwrite(f'crop_{i}.jpg', crop['image'])
```

### VisualizaÃ§Ã£o

```python
from src.yolo.visualization import visualize_detections

# Criar visualizaÃ§Ã£o
vis_image = visualize_detections(
    image,
    result['detections'],
    show_boxes=True,
    show_masks=True,
    show_confidence=True,
    thickness=2,
    alpha=0.3  # TransparÃªncia da mÃ¡scara
)

# Salvar ou exibir
cv2.imwrite('result.jpg', vis_image)
```

## ğŸ­ SegmentaÃ§Ã£o vs Detection

### Detection (Bounding Box)

```python
# Detection apenas
model = YOLO('yolov8n.pt')  # Sem '-seg'

# Output
detection = {
    'bbox': [100, 200, 300, 400],  # x1, y1, x2, y2
    'confidence': 0.95,
    'class': 0
}
```

**Vantagens:**
- âœ… Mais rÃ¡pido (~30% faster)
- âœ… Menor uso de memÃ³ria
- âœ… Mais simples

**Desvantagens:**
- âŒ Bounding box retangular (pode incluir fundo)
- âŒ Menos preciso para OCR

### Segmentation (InstÃ¢ncia)

```python
# Segmentation
model = YOLO('yolov8n-seg.pt')  # Com '-seg'

# Output
detection = {
    'bbox': [100, 200, 300, 400],
    'mask': np.array([[102, 203], [298, 205], ...]),  # PolÃ­gono
    'confidence': 0.95,
    'class': 0
}
```

**Vantagens:**
- âœ… Contorno preciso do objeto
- âœ… Remove fundo desnecessÃ¡rio
- âœ… Melhor para OCR (texto isolado)

**Desvantagens:**
- âŒ ~30% mais lento
- âŒ Maior uso de memÃ³ria

### Quando Usar Cada Um?

**Use Detection se:**
- Velocidade Ã© crÃ­tica
- RegiÃµes sÃ£o simples/retangulares
- Fundo nÃ£o interfere no OCR

**Use Segmentation se:** âœ… (Recomendado para Datalid)
- PrecisÃ£o Ã© importante
- RegiÃµes tÃªm formatos irregulares
- Fundo pode atrapalhar OCR
- Quer melhor qualidade de crop

## âš¡ OtimizaÃ§Ã£o

### OtimizaÃ§Ã£o de Velocidade

#### 1. Half Precision (FP16)
```python
model = YOLO('yolov8n-seg.pt')
model.to('cuda')

# Habilitar FP16
results = model.predict(
    'image.jpg',
    half=True  # 2x mais rÃ¡pido em GPUs modernas
)
```

#### 2. TensorRT (MÃ¡xima Performance)
```python
# Export para TensorRT
model.export(format='engine', half=True)

# Usar engine otimizado
model = YOLO('yolov8n-seg.engine')
results = model.predict('image.jpg')  # 3-5x mais rÃ¡pido
```

#### 3. Batch Processing
```python
# Processar mÃºltiplas imagens juntas
images = ['img1.jpg', 'img2.jpg', 'img3.jpg', 'img4.jpg']
results = model.predict(images, batch=4)  # Batch de 4
```

#### 4. Reduzir ResoluÃ§Ã£o
```yaml
detection:
  imgsz: 480  # Ao invÃ©s de 640 (25% mais rÃ¡pido)
```

### OtimizaÃ§Ã£o de PrecisÃ£o

#### 1. Aumentar ResoluÃ§Ã£o
```yaml
detection:
  imgsz: 1280  # Para objetos pequenos
```

#### 2. Test-Time Augmentation (TTA)
```python
results = model.predict(
    'image.jpg',
    augment=True  # Aplica mÃºltiplas transformaÃ§Ãµes e faz ensemble
)
```

#### 3. Ajustar Thresholds
```yaml
detection:
  conf: 0.15  # Reduzir para capturar mais detecÃ§Ãµes
  iou: 0.30   # Ajustar NMS para objetos prÃ³ximos
```

#### 4. Multi-Scale Inference
```python
# Inferir em mÃºltiplas escalas
results_640 = model.predict('image.jpg', imgsz=640)
results_1280 = model.predict('image.jpg', imgsz=1280)

# Combinar resultados (ensemble)
final_results = ensemble_results([results_640, results_1280])
```

### OtimizaÃ§Ã£o de MemÃ³ria

```python
# Processar em chunks para datasets grandes
from pathlib import Path

image_dir = Path('data/images')
chunk_size = 100

for i, chunk in enumerate(image_dir.glob('*.jpg')):
    if i % chunk_size == 0:
        # Processar chunk
        results = model.predict(chunk, stream=True)
        
        # Limpar memÃ³ria
        import gc
        gc.collect()
        torch.cuda.empty_cache()
```

## ğŸ“Š MÃ©tricas de Performance

### Benchmarks (GPU: RTX 3090)

| Modelo | Tamanho | FPS | mAP@50 | MemÃ³ria |
|--------|---------|-----|--------|---------|
| YOLOv8n-seg | 640 | 78 | 37.2 | 2.1 GB |
| YOLOv8n-seg | 1280 | 22 | 41.5 | 3.8 GB |
| YOLOv8s-seg | 640 | 58 | 44.6 | 2.8 GB |
| YOLOv8m-seg | 640 | 34 | 49.9 | 4.2 GB |

### Benchmarks (CPU: Intel i7-10700K)

| Modelo | Tamanho | FPS | Uso CPU |
|--------|---------|-----|---------|
| YOLOv8n-seg | 640 | 2.1 | 100% |
| YOLOv8n-seg | 480 | 3.5 | 100% |

## ğŸ› Troubleshooting

### Problema: CUDA Out of Memory

**SoluÃ§Ã£o:**
```yaml
detection:
  batch_size: 1  # Reduzir batch
  imgsz: 480     # Reduzir resoluÃ§Ã£o
  half: false    # Desabilitar FP16 se instÃ¡vel
```

### Problema: DetecÃ§Ãµes Faltando

**SoluÃ§Ãµes:**
1. Reduzir threshold de confianÃ§a
2. Aumentar resoluÃ§Ã£o de entrada
3. Verificar se a data estÃ¡ bem visÃ­vel na imagem
4. Considerar retreinar o modelo

### Problema: Muitas False Positives

**SoluÃ§Ãµes:**
1. Aumentar threshold de confianÃ§a
2. Ajustar NMS IoU threshold
3. Aplicar filtros de pÃ³s-processamento (tamanho, posiÃ§Ã£o)

## ğŸ“š ReferÃªncias

- [YOLOv8 Documentation](https://docs.ultralytics.com/)
- [YOLOv8 Paper](https://arxiv.org/abs/2305.09972)
- [Segmentation Guide](https://docs.ultralytics.com/tasks/segment/)

## ğŸ’¡ PrÃ³ximos Passos

- **[Treinamento YOLO](13-YOLO-TRAINING.md)** - Treinar modelo customizado
- **[PrÃ©-processamento](09-PREPROCESSING.md)** - Otimizar crops
- **[Sistema OCR](08-OCR-SYSTEM.md)** - Extrair texto das regiÃµes

---

**DÃºvidas sobre detecÃ§Ã£o YOLO?** Consulte [FAQ](25-FAQ.md) ou [Troubleshooting](22-TROUBLESHOOTING.md)

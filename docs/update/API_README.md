# ğŸš€ Datalid API

API REST completa e modular para detecÃ§Ã£o e extraÃ§Ã£o de datas de validade usando Deep Learning (YOLO) e OCR.

## âœ¨ CaracterÃ­sticas

### Core Features
- âœ… **DetecÃ§Ã£o de Datas** - YOLO segmentation para localizar regiÃµes de validade
- âœ… **MÃºltiplos Engines OCR** - Suporte para OpenOCR, PARSeq, TrOCR, Tesseract, EasyOCR, PaddleOCR
- âœ… **Parsing Inteligente** - ExtraÃ§Ã£o e validaÃ§Ã£o automÃ¡tica de datas
- âœ… **GPU Accelerated** - Suporte completo para CUDA
- âœ… **API REST** - FastAPI com documentaÃ§Ã£o automÃ¡tica
- âœ… **Cliente Python** - SDK fÃ¡cil de usar

### Recursos AvanÃ§ados
- ğŸ”„ **Processamento AssÃ­ncrono** - Sistema de jobs para processar em background
- ğŸ”Œ **WebSocket** - Processamento em tempo real com feedback de progresso
- ğŸ“Š **MÃ©tricas** - Monitoramento completo (Prometheus-compatible)
- ğŸ” **AutenticaÃ§Ã£o** - Suporte para API Keys e JWT
- âš¡ **Batch Processing** - Processar mÃºltiplas imagens de uma vez
- ğŸŒ **CORS** - ConfigurÃ¡vel para uso em webapps
- ğŸ“ **Logging** - Sistema robusto com Loguru
- ğŸ³ **Docker** - Deploy fÃ¡cil com Docker/Docker Compose

## ğŸš€ Quick Start

### 1. Instalar DependÃªncias

```bash
pip install -r requirements.txt
```

### 2. Iniciar Servidor

```bash
# Modo simples
python -m src.api.main

# Ou com o script
python scripts/api/start_server.py --dev

# Com configuraÃ§Ãµes personalizadas
python scripts/api/start_server.py \
  --host 0.0.0.0 \
  --port 8000 \
  --workers 4 \
  --device cuda:0 \
  --ocr-engine openocr
```

### 3. Acessar DocumentaÃ§Ã£o

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **OpenAPI Schema**: http://localhost:8000/openapi.json

### 4. Testar API

```bash
# Via script de teste
python scripts/api/test_api.py

# Via curl
curl -X POST "http://localhost:8000/process" \
  -F "file=@produto.jpg"
```

## ğŸ“– Uso BÃ¡sico

### Via Cliente Python

```python
from scripts.api.client import DatalidClient

# Criar cliente
client = DatalidClient("http://localhost:8000")

# Processar imagem
result = client.process_image("produto.jpg")

# Acessar resultados
if result['best_date']:
    print(f"Data: {result['best_date']['date']}")
    print(f"ConfianÃ§a: {result['best_date']['confidence']}")
    print(f"Dias atÃ© expirar: {result['best_date']['days_until_expiry']}")
    
    if result['best_date']['is_expired']:
        print("âš ï¸ Produto expirado!")
```

### Via HTTP/cURL

```bash
# Processar imagem
curl -X POST "http://localhost:8000/process" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@produto.jpg" \
  -F "detection_confidence=0.3" \
  -F "ocr_engine=openocr" \
  -F "return_visualization=true"

# Health check
curl http://localhost:8000/health

# InformaÃ§Ãµes
curl http://localhost:8000/info

# MÃ©tricas
curl http://localhost:8000/v2/metrics
```

## ğŸ”Œ Endpoints Principais

### API v1

| Endpoint | MÃ©todo | DescriÃ§Ã£o |
|----------|--------|-----------|
| `/` | GET | Root endpoint |
| `/health` | GET | Health check |
| `/info` | GET | InformaÃ§Ãµes da API |
| `/process` | POST | Processar uma imagem |
| `/process/batch` | POST | Processar mÃºltiplas imagens |
| `/process/url` | POST | Processar imagem de URL |

### API v2 (Recursos AvanÃ§ados)

| Endpoint | MÃ©todo | DescriÃ§Ã£o |
|----------|--------|-----------|
| `/v2/ws` | WS | WebSocket para tempo real |
| `/v2/jobs` | POST | Criar job assÃ­ncrono |
| `/v2/jobs/{id}` | GET | Status do job |
| `/v2/jobs` | GET | Listar jobs |
| `/v2/jobs/{id}` | DELETE | Cancelar job |
| `/v2/metrics` | GET | MÃ©tricas do sistema |
| `/v2/metrics/endpoints` | GET | MÃ©tricas por endpoint |
| `/v2/metrics/prometheus` | GET | Formato Prometheus |

## ğŸ“¦ Exemplos AvanÃ§ados

### Processamento em Batch

```python
client = DatalidClient("http://localhost:8000")

# Processar mÃºltiplas imagens
results = client.process_batch([
    "produto1.jpg",
    "produto2.jpg",
    "produto3.jpg"
])

print(f"Sucesso: {results['successful']}/{results['total_images']}")

for res in results['results']:
    if res['success'] and res['result']['best_date']:
        print(f"{res['filename']}: {res['result']['best_date']['date']}")
```

### Jobs AssÃ­ncronos

```python
# Criar job
job = client.create_job("produto.jpg")
print(f"Job ID: {job['job_id']}")

# Aguardar conclusÃ£o
result = client.wait_for_job(job['job_id'])

# Ou de forma mais simples
result = client.process_image_async("produto.jpg")
```

### WebSocket (JavaScript)

```javascript
const ws = new WebSocket('ws://localhost:8000/v2/ws');

ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  
  if (data.type === 'progress') {
    console.log(`Progresso: ${data.progress * 100}%`);
  }
  
  if (data.type === 'result') {
    console.log('Data encontrada:', data.data.best_date.date);
  }
};

// Enviar imagem
ws.send(JSON.stringify({
  type: 'process',
  image: imageBase64
}));
```

## âš™ï¸ ConfiguraÃ§Ã£o

### Arquivo .env

Copie `.env.example` para `.env` e ajuste:

```env
# Servidor
HOST=0.0.0.0
PORT=8000
WORKERS=1

# AutenticaÃ§Ã£o
AUTH_ENABLED=false
API_KEYS=["key1","key2"]

# Modelos
MODEL_DEVICE=0  # 0 para GPU, cpu para CPU
DEFAULT_OCR_ENGINE=openocr
DEFAULT_CONFIDENCE=0.25

# Limites
MAX_FILE_SIZE_MB=10
MAX_BATCH_SIZE=50
RATE_LIMIT_REQUESTS=60

# Logging
LOG_LEVEL=INFO
DEBUG=false
```

### ConfiguraÃ§Ã£o ProgramÃ¡tica

```python
from src.api.config import APISettings

settings = APISettings(
    host="0.0.0.0",
    port=8080,
    default_ocr_engine="parseq",
    max_file_size_mb=20
)
```

## ğŸ³ Docker

### Build

```bash
docker build -t datalid-api .
```

### Run

```bash
docker run -p 8000:8000 \
  -v $(pwd)/models:/app/models \
  -e MODEL_DEVICE=0 \
  --gpus all \
  datalid-api
```

### Docker Compose

```yaml
version: '3.8'
services:
  api:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./models:/app/models
      - ./config:/app/config
    environment:
      - LOG_LEVEL=INFO
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

## ğŸ“Š Monitoramento

### Prometheus

```yaml
scrape_configs:
  - job_name: 'datalid-api'
    static_configs:
      - targets: ['localhost:8000']
    metrics_path: '/v2/metrics/prometheus'
```

### MÃ©tricas DisponÃ­veis

- `datalid_uptime_seconds` - Uptime da API
- `datalid_requests_total` - Total de requisiÃ§Ãµes
- `datalid_errors_total` - Total de erros
- `datalid_images_processed_total` - Imagens processadas
- `datalid_dates_found_total` - Datas encontradas
- `datalid_processing_time_seconds` - Tempo mÃ©dio de processamento
- `datalid_requests_per_minute` - Taxa de requisiÃ§Ãµes
- `datalid_error_rate_percent` - Taxa de erro

## ğŸ” AutenticaÃ§Ã£o

### API Key

```python
# No .env
AUTH_ENABLED=true
API_KEYS=["chave-secreta-1","chave-secreta-2"]

# No cliente
client = DatalidClient(
    "http://localhost:8000",
    api_key="chave-secreta-1"
)
```

```bash
# Via curl
curl -H "X-API-Key: chave-secreta-1" \
  http://localhost:8000/process ...
```

## ğŸ“š DocumentaÃ§Ã£o Completa

- **[Guia Completo](docs/API_COMPLETE_GUIDE.md)** - DocumentaÃ§Ã£o detalhada
- **[API Reference](docs/API.md)** - ReferÃªncia de endpoints
- **[Quick Start](docs/API_QUICK_START.md)** - InÃ­cio rÃ¡pido
- **[Exemplos](examples/api_usage.py)** - CÃ³digo de exemplo

## ğŸ› ï¸ Desenvolvimento

### Rodar em Modo Debug

```bash
python scripts/api/start_server.py --dev
```

### Testes

```bash
# Teste rÃ¡pido
python scripts/api/test_api.py

# Testes completos
pytest tests/api/

# Com cobertura
pytest tests/api/ --cov=src/api
```

### Formato de CÃ³digo

```bash
black src/api/
isort src/api/
flake8 src/api/
```

## ğŸ—ï¸ Arquitetura

```
src/api/
â”œâ”€â”€ __init__.py          # Exports principais
â”œâ”€â”€ main.py              # AplicaÃ§Ã£o FastAPI
â”œâ”€â”€ config.py            # ConfiguraÃ§Ãµes (Pydantic Settings)
â”œâ”€â”€ routes.py            # Endpoints API v1
â”œâ”€â”€ routes_v2.py         # Endpoints API v2
â”œâ”€â”€ schemas.py           # Modelos Pydantic
â”œâ”€â”€ service.py           # LÃ³gica de processamento
â”œâ”€â”€ auth.py              # AutenticaÃ§Ã£o
â”œâ”€â”€ middleware.py        # Middlewares
â”œâ”€â”€ websocket.py         # WebSocket handlers
â”œâ”€â”€ jobs.py              # Sistema de jobs
â”œâ”€â”€ metrics.py           # MÃ©tricas e monitoramento
â””â”€â”€ utils.py             # UtilitÃ¡rios
```

## ğŸ“ˆ Performance

### Benchmarks

- **DetecÃ§Ã£o**: ~200-500ms (GPU)
- **OCR**: ~300-800ms dependendo do engine
- **Total**: ~0.5-1.5s por imagem

### OtimizaÃ§Ãµes

- Use GPU para melhor performance (`MODEL_DEVICE=0`)
- Configure batch processing para mÃºltiplas imagens
- Use jobs assÃ­ncronos para nÃ£o bloquear
- Ajuste `detection_confidence` conforme necessÃ¡rio
- Cache de modelos automÃ¡tico

## ğŸ†˜ Troubleshooting

### API nÃ£o inicia

```bash
# Verificar porta
lsof -i :8000  # Linux/Mac
netstat -ano | findstr :8000  # Windows

# Ver logs
tail -f logs/api.log
```

### Erro de memÃ³ria GPU

```bash
# Usar CPU
MODEL_DEVICE=cpu python -m src.api.main

# Ou reduzir batch size
MAX_BATCH_SIZE=10
```

### Performance lenta

- Verificar se estÃ¡ usando GPU
- Reduzir resoluÃ§Ã£o das imagens
- Usar OCR engine mais rÃ¡pido (parseq_tiny)
- Aumentar `detection_confidence`

## ğŸ“„ LicenÃ§a

[Sua licenÃ§a aqui]

## ğŸ¤ Contribuindo

Contributions sÃ£o bem-vindas! Por favor leia [CONTRIBUTING.md](docs/CONTRIBUTING.md).

## ğŸ“§ Suporte

- ğŸ“– DocumentaÃ§Ã£o: [docs/](docs/)
- ğŸ› Issues: [GitHub Issues]
- ğŸ’¬ DiscussÃµes: [GitHub Discussions]

---

Feito com â¤ï¸ usando FastAPI, YOLO, e mÃºltiplos engines de OCR.

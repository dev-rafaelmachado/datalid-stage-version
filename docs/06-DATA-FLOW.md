# üåä Fluxo de Dados

> Jornada completa dos dados pelo sistema Datalid 3.0

## üìã √çndice

- [Vis√£o Geral](#vis√£o-geral)
- [Fluxo Detalhado](#fluxo-detalhado)
- [Transforma√ß√µes de Dados](#transforma√ß√µes-de-dados)
- [Estados dos Dados](#estados-dos-dados)
- [Armazenamento e Cache](#armazenamento-e-cache)

## üéØ Vis√£o Geral

```mermaid
graph TD
    A[Imagem de Entrada] --> B[YOLO Detection]
    B --> C[Crop da Regi√£o]
    C --> D[Pr√©-processamento]
    D --> E[OCR Engine]
    E --> F[Texto Bruto]
    F --> G[Parse de Data]
    G --> H[Valida√ß√£o]
    H --> I[Resultado Final]
    
    B --> J[Metadata: BBox, Mask]
    D --> K[Imagem Otimizada]
    E --> L[Confian√ßa OCR]
    G --> M[Data Estruturada]
    H --> N[Score Final]
```

## üîÑ Fluxo Detalhado

### Etapa 1: Entrada de Dados

**Input:** Imagem do produto (JPEG, PNG, etc.)

```python
# Formato de entrada
{
    "image_path": "/path/to/image.jpg",
    "image_data": np.ndarray,  # Shape: (H, W, 3), dtype: uint8
    "metadata": {
        "width": 1920,
        "height": 1080,
        "format": "JPEG",
        "size_bytes": 524288
    }
}
```

**Transforma√ß√µes:**
1. Leitura do arquivo via OpenCV
2. Convers√£o de BGR para RGB
3. Normaliza√ß√£o de canais (0-255)
4. Opcional: Redimensionamento se > max_size

### Etapa 2: Detec√ß√£o YOLO

**Processo:**

```python
# Input
image_rgb: np.ndarray  # Shape: (H, W, 3)

# YOLO Processing
preprocessed = yolo_preprocess(image_rgb)  # Normaliza√ß√£o, padding
predictions = model.predict(preprocessed)
detections = nms_filter(predictions, conf=0.25, iou=0.45)

# Output
{
    "detections": [
        {
            "bbox": [x1, y1, x2, y2],  # Coordenadas absolutas
            "confidence": 0.94,
            "class_id": 0,
            "class_name": "expiry_date",
            "mask": np.ndarray,  # Shape: (N, 2), pol√≠gono
            "area": 12500  # pixels
        }
    ],
    "inference_time": 0.32  # segundos
}
```

**Transforma√ß√µes:**
1. Redimensionamento para 640x640 (ou imgsz configurado)
2. Padding para manter aspect ratio
3. Normaliza√ß√£o (0-1)
4. Inference no modelo
5. Post-processing (NMS, thresholding)
6. Convers√£o de coordenadas relativas para absolutas

### Etapa 3: Extra√ß√£o de Regi√£o (Crop)

**Processo:**

```python
# Para cada detec√ß√£o
for detection in detections:
    # Expandir bounding box com padding
    x1, y1, x2, y2 = expand_bbox(
        detection['bbox'], 
        padding=10,
        img_shape=(H, W)
    )
    
    # Crop da regi√£o
    crop = image_rgb[y1:y2, x1:x2]
    
    # Opcional: aplicar m√°scara de segmenta√ß√£o
    if use_mask:
        mask = detection['mask']
        crop = apply_polygon_mask(crop, mask)
```

**Output:**
```python
{
    "crop_id": 0,
    "image": np.ndarray,  # Shape: (h, w, 3)
    "original_bbox": [x1, y1, x2, y2],
    "crop_size": (165, 55),
    "detection_confidence": 0.94
}
```

### Etapa 4: Pr√©-processamento

**Pipeline de transforma√ß√µes:**

```python
crop_processed = crop.copy()

# 1. Corre√ß√£o de perspectiva (se necess√°rio)
if config.deskew:
    crop_processed = deskew_image(crop_processed)

# 2. Redimensionamento (manter legibilidade)
if config.resize:
    crop_processed = smart_resize(
        crop_processed,
        max_height=64,
        maintain_aspect=True
    )

# 3. Normaliza√ß√£o de cor
if config.normalize:
    crop_processed = normalize_channels(crop_processed)

# 4. Melhoria de contraste
if config.clahe:
    crop_processed = apply_clahe(
        crop_processed,
        clip_limit=2.0,
        tile_size=8
    )

# 5. Remo√ß√£o de ru√≠do
if config.denoise:
    crop_processed = denoise(crop_processed, strength=5)

# 6. Aumento de nitidez
if config.sharpen:
    crop_processed = sharpen(crop_processed, amount=1.5)

# 7. Binariza√ß√£o adaptativa
if config.binarize:
    crop_processed = adaptive_threshold(
        crop_processed,
        block_size=11,
        c=2
    )
```

**Output:**
```python
{
    "preprocessed_image": np.ndarray,  # Otimizado para OCR
    "transformations_applied": [
        "clahe", "denoise", "sharpen", "binarize"
    ],
    "final_size": (128, 48)
}
```

### Etapa 5: OCR

**Processo por Engine:**

#### OpenOCR
```python
# Input: preprocessed_image (RGB ou grayscale)
text, confidence = openocr_engine.recognize(preprocessed_image)

# Output
{
    "engine": "openocr",
    "text": "VAL 15/03/2025",
    "confidence": 0.92,
    "inference_time": 0.8
}
```

#### PARSeq
```python
# Requer PIL Image
pil_image = Image.fromarray(preprocessed_image)
text, confidence = parseq_engine.recognize(pil_image)

# Output
{
    "engine": "parseq",
    "text": "VAL 15/03/2025",
    "confidence": 0.89,
    "character_confidences": [0.95, 0.91, 0.88, ...],
    "inference_time": 0.6
}
```

**Estrutura de sa√≠da unificada:**
```python
{
    "ocr_results": [
        {
            "crop_id": 0,
            "engine": "openocr",
            "text": "VAL 15/03/2025",
            "confidence": 0.92,
            "bounding_boxes": [  # Algumas engines retornam
                {"char": "V", "bbox": [0, 0, 10, 20], "conf": 0.95},
                {"char": "A", "bbox": [12, 0, 22, 20], "conf": 0.93},
                ...
            ],
            "alternatives": [  # Beam search top-k
                {"text": "VAL 15/03/2025", "conf": 0.92},
                {"text": "VAL 15/03/2026", "conf": 0.05}
            ]
        }
    ]
}
```

### Etapa 6: Parse de Data

**Processo:**

```python
from src.ocr.postprocessors import DateParser

parser = DateParser(config)

for ocr_result in ocr_results:
    text = ocr_result['text']
    
    # 1. Limpeza de texto
    cleaned = clean_text(text)
    # "VAL 15/03/2025" -> "15/03/2025"
    
    # 2. Extra√ß√£o de padr√µes
    date_candidates = extract_date_patterns(cleaned)
    # ["15/03/2025", "15-03-2025", "15.03.2025"]
    
    # 3. Parse com formatos conhecidos
    parsed_dates = []
    for candidate in date_candidates:
        for fmt in date_formats:
            try:
                date_obj = datetime.strptime(candidate, fmt)
                parsed_dates.append({
                    "date": date_obj,
                    "format": fmt,
                    "original_text": candidate
                })
            except ValueError:
                continue
    
    # 4. Valida√ß√£o
    valid_dates = validate_dates(parsed_dates)
    # Remove datas imposs√≠veis (ano < 2020, > 2050, etc.)
    
    # 5. Scoring
    scored_dates = score_dates(valid_dates, ocr_result['confidence'])
```

**Output:**
```python
{
    "parsed_dates": [
        {
            "date": "15/03/2025",
            "date_object": datetime(2025, 3, 15),
            "format": "%d/%m/%Y",
            "confidence": 0.93,
            "original_text": "VAL 15/03/2025",
            "days_until_expiry": 127,
            "is_expired": False,
            "is_valid": True,
            "validation_checks": {
                "format_valid": True,
                "date_reasonable": True,
                "in_future": True
            }
        }
    ]
}
```

### Etapa 7: Sele√ß√£o da Melhor Data

**Crit√©rios de sele√ß√£o:**

```python
def select_best_date(parsed_dates):
    """
    Seleciona a melhor data baseado em m√∫ltiplos crit√©rios.
    """
    if not parsed_dates:
        return None
    
    # Scoring composto
    for date in parsed_dates:
        score = 0.0
        
        # 1. Confian√ßa do OCR (peso: 40%)
        score += 0.4 * date['confidence']
        
        # 2. Formato comum (peso: 20%)
        if date['format'] in COMMON_FORMATS:
            score += 0.2
        
        # 3. Data futura razo√°vel (peso: 20%)
        days = date['days_until_expiry']
        if 0 < days < 730:  # 2 anos
            score += 0.2 * (1 - abs(days - 365) / 365)
        
        # 4. Consist√™ncia (peso: 20%)
        # Se m√∫ltiplas datas, favorecer a mais comum
        score += 0.2 * date['occurrence_count'] / max_occurrences
        
        date['final_score'] = score
    
    # Retornar data com maior score
    return max(parsed_dates, key=lambda x: x['final_score'])
```

**Output Final:**
```python
{
    "best_date": {
        "date": "15/03/2025",
        "confidence": 0.93,
        "days_until_expiry": 127,
        "is_expired": False,
        "expiry_status": "valid",
        "warning_level": "none",  # none, near_expiry, expired
        "source": {
            "detection_bbox": [120, 340, 285, 395],
            "detection_confidence": 0.94,
            "ocr_engine": "openocr",
            "ocr_confidence": 0.92,
            "format_detected": "DD/MM/YYYY"
        }
    },
    "all_candidates": [...],  # Todas as datas encontradas
    "processing_time": {
        "detection": 0.32,
        "preprocessing": 0.12,
        "ocr": 0.81,
        "parsing": 0.02,
        "total": 1.27
    }
}
```

## üìä Estados dos Dados

### Estado 1: Imagem Original
- **Formato:** RGB ou BGR array
- **Shape:** (H, W, 3)
- **Dtype:** uint8
- **Range:** 0-255
- **Tamanho:** ~1-5 MB (JPEG comprimido)

### Estado 2: Imagem YOLO-Preprocessed
- **Formato:** RGB float32
- **Shape:** (640, 640, 3) ou (imgsz, imgsz, 3)
- **Dtype:** float32
- **Range:** 0-1
- **Transforma√ß√µes:** Redimensionamento + padding + normaliza√ß√£o

### Estado 3: Crop de Regi√£o
- **Formato:** RGB uint8
- **Shape:** (h, w, 3), tipicamente (40-100, 80-300, 3)
- **Dtype:** uint8
- **Range:** 0-255
- **Tamanho:** ~10-50 KB

### Estado 4: Crop Pr√©-processado
- **Formato:** RGB ou Grayscale
- **Shape:** (h', w', c) onde c=1 ou 3
- **Dtype:** uint8
- **Range:** 0-255 ou bin√°rio (0, 255)
- **Transforma√ß√µes:** CLAHE + denoise + sharpen + binarize

### Estado 5: Texto Extra√≠do
- **Formato:** String UTF-8
- **Conte√∫do:** "VAL 15/03/2025"
- **Metadata:** Confidence score, bounding boxes

### Estado 6: Data Estruturada
- **Formato:** datetime object + metadata
- **Componentes:** day, month, year
- **Valida√ß√£o:** Checks aplicados
- **Score:** Confian√ßa final

## üíæ Armazenamento e Cache

### Estrutura de Outputs

```
outputs/
‚îú‚îÄ‚îÄ pipeline/
‚îÇ   ‚îú‚îÄ‚îÄ image1_result.jpg           # Visualiza√ß√£o final
‚îÇ   ‚îú‚îÄ‚îÄ image1_results.json         # Dados estruturados
‚îÇ   ‚îú‚îÄ‚îÄ image1_crop_0.jpg          # Crop da regi√£o
‚îÇ   ‚îî‚îÄ‚îÄ image1_preprocessed_0.jpg  # Ap√≥s pr√©-processamento
‚îÇ
‚îú‚îÄ‚îÄ pipeline_steps/
‚îÇ   ‚îú‚îÄ‚îÄ 001_original.jpg
‚îÇ   ‚îú‚îÄ‚îÄ 002_detection.jpg
‚îÇ   ‚îú‚îÄ‚îÄ 003_crop.jpg
‚îÇ   ‚îú‚îÄ‚îÄ 004_preprocessed.jpg
‚îÇ   ‚îî‚îÄ‚îÄ 005_final.jpg
‚îÇ
‚îî‚îÄ‚îÄ logs/
    ‚îî‚îÄ‚îÄ pipeline_YYYYMMDD_HHMMSS.log
```

### Cache de Modelos

```python
# Modelos YOLO s√£o cached automaticamente
cache_dir = Path.home() / ".cache" / "datalid"
yolo_cache = cache_dir / "yolo" / "yolov8n-seg.pt"

# Modelos OCR (torch.hub)
torch_cache = Path.home() / ".cache" / "torch" / "hub"
parseq_cache = torch_cache / "baudm_parseq_main"
```

### Metadata Persistida

```json
{
    "session_id": "uuid-123",
    "timestamp": "2024-11-08T14:30:00",
    "config": {
        "detection": {...},
        "ocr": {...},
        "parsing": {...}
    },
    "results": [...],
    "statistics": {
        "total_images": 100,
        "successful": 95,
        "failed": 5,
        "avg_processing_time": 1.2,
        "avg_confidence": 0.91
    }
}
```

## üîÑ Transforma√ß√µes de Dados - Resumo Visual

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Imagem Original ‚îÇ  RGB, (1920x1080x3), 2.5MB
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ resize + normalize
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ YOLO Input      ‚îÇ  RGB float, (640x640x3), normalized
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ inference
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Detections      ‚îÇ  BBox + Mask + Confidence
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ crop
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Crop            ‚îÇ  RGB, (165x55x3), 28KB
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ CLAHE + denoise + binarize
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Preprocessed    ‚îÇ  Grayscale, (165x55), optimized for OCR
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ OCR inference
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Text            ‚îÇ  "VAL 15/03/2025", conf=0.92
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ regex + parse
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Date Object     ‚îÇ  datetime(2025, 3, 15)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ validate + score
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Final Result    ‚îÇ  {date, confidence, days_to_expiry, ...}
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìà M√©tricas de Fluxo

### Throughput T√≠pico
- **Detec√ß√£o YOLO:** ~3 FPS (GPU), ~0.5 FPS (CPU)
- **OCR:** ~1.2 segundos/crop (varia por engine)
- **Parse:** ~0.02 segundos
- **Total:** ~1-2 segundos/imagem (GPU)

### Tamanhos de Dados
- **Input:** 1-5 MB (imagem JPEG)
- **Mem√≥ria YOLO:** ~500 MB (modelo + tensors)
- **Mem√≥ria OCR:** ~1-2 GB (depende do engine)
- **Output JSON:** ~2-10 KB

### Bottlenecks
1. üêå **OCR inference** (70% do tempo total)
2. üêå **Carregamento de modelos** (inicializa√ß√£o)
3. üêå **I/O de disco** (se muitas visualiza√ß√µes)

## üí° Otimiza√ß√µes

### Batch Processing
```python
# Processar m√∫ltiplas imagens juntas
results = pipeline.process_batch([img1, img2, img3])
# Compartilha overhead de inicializa√ß√£o
```

### Cache de Preprocessamento
```python
# Cache de crops j√° processados
crop_cache = {}
cache_key = hash(crop.tobytes())
if cache_key in crop_cache:
    preprocessed = crop_cache[cache_key]
```

### Lazy Loading de OCR Engines
```python
# S√≥ carrega engine quando necess√°rio
engine = get_or_load_engine(engine_name)
```

## üìö Pr√≥ximos Passos

- **[Arquitetura do Sistema](04-ARCHITECTURE.md)** - Componentes e intera√ß√µes
- **[Sistema OCR](08-OCR-SYSTEM.md)** - Detalhes dos engines OCR
- **[Pr√©-processamento](09-PREPROCESSING.md)** - T√©cnicas de otimiza√ß√£o de imagens

---

**D√∫vidas sobre o fluxo de dados?** Consulte [FAQ](25-FAQ.md) ou [Troubleshooting](22-TROUBLESHOOTING.md)

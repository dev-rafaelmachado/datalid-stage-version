# ========================================
# üìä Configura√ß√£o: Avalia√ß√£o da Pipeline Completa
# ========================================

name: pipeline_evaluation
description: "Avalia√ß√£o end-to-end da pipeline: YOLO ‚Üí OCR ‚Üí Parsing"

# Dataset de Avalia√ß√£o
dataset:
  # Caminho para as imagens de teste
  images_dir: data/raw/TCC_DATESET_V2-6/train/images
  
  # Ground truth com labels finais (datas extra√≠das)
  ground_truth: data/evaluation/ground_truth.json
  
  # N√∫mero de imagens para testar (null = todas)
  num_images: null  # Usar todas as imagens dispon√≠veis
  
  # Modo de sele√ß√£o: 'first', 'random', 'all'
  selection_mode: random
  
  # Seed para sele√ß√£o aleat√≥ria (reprodutibilidade)
  random_seed: 42

# Pipeline Configuration
pipeline:
  # Usar configura√ß√£o existente da pipeline
  config_file: config/pipeline/full_pipeline.yaml
  
  # Salvar outputs intermedi√°rios de cada etapa
  save_intermediate_steps: true
  
  # Verbose (mostrar detalhes durante processamento)
  verbose: true

# M√©tricas para Avaliar
metrics:
  # M√©tricas de Detec√ß√£o (YOLO)
  detection:
    enabled: true
    metrics:
      - detection_rate      # % de imagens com pelo menos 1 detec√ß√£o
      - avg_detections      # N√∫mero m√©dio de detec√ß√µes por imagem
      - avg_confidence      # Confian√ßa m√©dia das detec√ß√µes
  
  # M√©tricas de OCR
  ocr:
    enabled: true
    metrics:
      - exact_match         # Match exato da string
      - partial_match       # Match parcial (>50% similaridade)
      - character_error_rate  # CER
      - word_error_rate     # WER
      - similarity          # Similaridade (0-1)
  
  # M√©tricas de Parsing de Data
  date_parsing:
    enabled: true
    metrics:
      - date_found          # % de datas encontradas
      - date_valid          # % de datas v√°lidas
      - component_accuracy  # Acur√°cia por componente (dia/m√™s/ano)
      - format_match        # Match do formato da data
  
  # M√©tricas End-to-End
  end_to_end:
    enabled: true
    metrics:
      - pipeline_accuracy   # % de datas corretas no final
      - full_match          # Match completo (data id√™ntica)
      - date_component_match  # Pelo menos 1 componente correto
      - avg_processing_time # Tempo m√©dio por imagem

# An√°lise de Erros
error_analysis:
  # Identificar padr√µes de erro
  enabled: true
  
  # Classificar erros por etapa
  classify_by_stage: true
  
  # Salvar exemplos de erros
  save_error_examples: true
  max_error_examples: 20
  
  # An√°lise detalhada
  detailed_analysis:
    # An√°lise por tipo de erro
    by_error_type: true
    
    # An√°lise por dificuldade da imagem
    by_difficulty: false
    
    # Casos espec√≠ficos
    edge_cases: true

# Outputs
output:
  # Diret√≥rio base de sa√≠da
  base_dir: outputs/pipeline_evaluation
  
  # Criar subdiret√≥rio com timestamp
  use_timestamp: true
  
  # Salvar resultados
  save_results:
    # CSV com resultados detalhados por imagem
    detailed_csv: true
    
    # JSON com resultados completos
    full_json: true
    
    # Relat√≥rio markdown
    markdown_report: true
    
    # M√©tricas agregadas (JSON)
    metrics_summary: true
  
  # Salvar visualiza√ß√µes
  save_visualizations:
    # Gr√°ficos de m√©tricas
    metrics_plots: true
    
    # Confusion matrices
    confusion_matrix: true
    
    # Distribui√ß√µes de erro
    error_distributions: true
    
    # Exemplos de sucesso/falha
    example_images: true
    
    # Compara√ß√£o com ground truth
    comparison_plots: true
  
  # Salvar steps intermedi√°rios por imagem
  save_intermediate_steps:
    enabled: true
    steps:
      - input_image
      - yolo_detection
      - segmentation_masks
      - crops_original
      - crops_preprocessed
      - ocr_results
      - parsed_dates
      - final_result

# Compara√ß√£o com Baseline
comparison:
  # Comparar com resultados anteriores (OCR standalone)
  enabled: false
  
  # Resultados anteriores para comparar
  baseline_results:
    - outputs/ocr_benchmarks/openocr/openocr_results.csv
  
  # M√©tricas para comparar
  compare_metrics:
    - exact_match
    - character_error_rate
    - processing_time

# Valida√ß√£o
validation:
  # Formato esperado do ground truth
  ground_truth_format:
    type: json  # json ou csv
    encoding: utf-8
    
    # Para JSON - Suporta dois formatos:
    # Formato 1 (antigo): {"annotations": {"image.jpg": "text", ...}}
    # Formato 2 (novo):   {"detection_id": {"image": "image.jpg", "expiry_date": "...", ...}, ...}
    json_key: annotations  # Key que cont√©m as anota√ß√µes (opcional para formato 2)
    field_name: expiry_date  # Nome do campo com a data de validade (para formato 2)
    
    # Mapeamento de campos
    fields:
      image_id: filename  # Campo com nome/id da imagem
      label: text         # Campo com texto esperado (formato 1)
      expiry: expiry_date # Campo com data de validade (formato 2)
  
  # Normaliza√ß√£o de texto
  text_normalization:
    # Remover espa√ßos extras
    strip_whitespace: true
    
    # Converter para lowercase para compara√ß√£o
    lowercase: false
    
    # Normalizar caracteres especiais
    normalize_special_chars: false
    
    # Remover pontua√ß√£o para compara√ß√£o
    remove_punctuation: false

# Configura√ß√µes de Processamento
processing:
  # Processar em lote (batch)
  batch_processing: false
  batch_size: 1
  
  # N√∫mero de workers (paralelo)
  num_workers: 1
  
  # Continuar em caso de erro
  continue_on_error: true
  
  # Timeout por imagem (segundos)
  timeout_per_image: 60
  
  # Mostrar progresso
  show_progress: true

# Logging
logging:
  # N√≠vel de log
  level: INFO  # DEBUG, INFO, WARNING, ERROR
  
  # Salvar log em arquivo
  save_to_file: true
  
  # Arquivo de log
  log_file: outputs/pipeline_evaluation/evaluation.log
  
  # Log detalhado por imagem
  log_per_image: false
